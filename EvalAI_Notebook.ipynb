{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84533f98",
   "metadata": {},
   "source": [
    "# Avalia√ß√£o de Modelos de IA para Consultas Jur√≠dicas Brasileiras\n",
    "\n",
    "Este notebook permite executar o pipeline de avalia√ß√£o de modelos de IA especializados em direito brasileiro. Ele inclui setup completo, configura√ß√£o de cache e execu√ß√£o intuitiva baseada no script `run.py`.\n",
    "\n",
    "## Pr√©-requisitos\n",
    "- Conta no OpenRouter para API key\n",
    "- Ambiente Colab ou Jupyter com acesso a GPU (recomendado)\n",
    "\n",
    "## Passos do Setup\n",
    "1. Definir API key do OpenRouter\n",
    "2. Clonar reposit√≥rio\n",
    "3. Instalar depend√™ncias\n",
    "4. Configurar cache do Hugging Face\n",
    "5. Executar avalia√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440b9c0",
   "metadata": {},
   "source": [
    "## 1. Definir API Key do OpenRouter\n",
    "\n",
    "Execute a c√©lula abaixo e insira sua API key quando solicitado. Ela ser√° armazenada como vari√°vel de ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Solicitar API key do usu√°rio\n",
    "api_key = input(\"Digite sua API key do OpenRouter: \")\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "print(\"API key definida com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826add1",
   "metadata": {},
   "source": [
    "## 2. Clonar Reposit√≥rio\n",
    "\n",
    "Clone o reposit√≥rio oficial do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/expagepay/EvalAItoNomartiveConsults.git\n",
    "%cd /content/EvalAItoNomartiveConsults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12d184",
   "metadata": {},
   "source": [
    "## 3. Instalar Depend√™ncias\n",
    "\n",
    "Instale todas as bibliotecas necess√°rias do arquivo `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e3529",
   "metadata": {},
   "source": [
    "## 4. Configurar Cache do Hugging Face\n",
    "\n",
    "Configure o cache para otimizar downloads de modelos e evitar re-downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227066e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configurar caminhos de cache (adaptado para Colab/Linux)\n",
    "cache_dir = '/content/HF_Cache'\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "os.environ['HF_HUB_CACHE'] = cache_dir\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HF_HUB_CACHE'] = os.path.join(cache_dir, 'models')\n",
    "\n",
    "print(f\"Cache configurado em: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108b455",
   "metadata": {},
   "source": [
    "## 5. Executar Avalia√ß√£o\n",
    "\n",
    "Agora voc√™ pode executar o pipeline de avalia√ß√£o usando os argumentos do `run.py`. Aqui est√£o algumas op√ß√µes:\n",
    "\n",
    "### Op√ß√µes de Execu√ß√£o:\n",
    "- `--quick_eval`: Avalia√ß√£o r√°pida com conjunto padr√£o de perguntas\n",
    "- `--perguntas \"Pergunta 1\" \"Pergunta 2\"`: Lista de perguntas (use aspas para espa√ßos)\n",
    "- `--ground_truth \"Resposta 1\" \"Resposta 2\"`: Respostas ideais (opcional, use \"\" para vazio)\n",
    "- `--csv_file arquivo.csv`: Arquivo CSV com perguntas e ground truths\n",
    "- `--num_queries N`: N√∫mero de queries por pergunta (padr√£o: 3)\n",
    "- `--modelos modelo1 modelo2`: Lista de modelos a comparar\n",
    "\n",
    "### Exemplos:\n",
    "- Avalia√ß√£o r√°pida: `!python run.py --quick_eval`\n",
    "- Com perguntas customizadas: `!python run.py --perguntas \"O que √© a LGPD?\" \"Direitos do consumidor\" --ground_truth \"Lei de prote√ß√£o de dados\" \"\"`\n",
    "- Com CSV: `!python run.py --csv_file meu_arquivo.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e231ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Avalia√ß√£o r√°pida\n",
    "!python run.py --quick_eval --num_queries 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296cc4ab",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Ap√≥s a execu√ß√£o, os resultados ser√£o salvos em:\n",
    "- `resultados.csv`: Dados tabulares\n",
    "- `resultados.json`: Dados estruturados\n",
    "- `comparacao_modelos.json`: Compara√ß√£o entre modelos\n",
    "- `report.py`: Gera relat√≥rio detalhado\n",
    "\n",
    "Para visualizar os resultados, execute o relat√≥rio:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4645ab",
   "metadata": {},
   "source": [
    "## 6. Modo de Tratamento de Contexto\n",
    "\n",
    "O par√¢metro `--modo_contexto` controla como o sistema lida com contextos muito grandes que podem exceder o limite de tokens dos modelos:\n",
    "\n",
    "- **`truncar`** (padr√£o): Aplica truncamento regressivo do contexto (700k ‚Üí 100k ‚Üí 50k ‚Üí 28k) at√© que a chamada seja bem-sucedida.\n",
    "- **`resumir`**: Gera um resumo do contexto usando Gemini 2.5 Flash, preservando detalhes essenciais sem inventar informa√ß√µes.\n",
    "\n",
    "### Exemplos com Modo de Contexto:\n",
    "- Avalia√ß√£o r√°pida com truncamento: `!python run.py --quick_eval --modo_contexto truncar`\n",
    "- Avalia√ß√£o r√°pida com resumo: `!python run.py --quick_eval --modo_contexto resumir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo com resumo de contexto\n",
    "!python run.py --quick_eval --modo_contexto resumir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407408f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relat√≥rio\n",
    "!python report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar Resultados e Issues\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "results_path = 'results/resultados.json'\n",
    "comparacao_path = 'results/comparacao_modelos.json'\n",
    "\n",
    "try:\n",
    "    # Carregar compara√ß√£o para tabela e vencedor\n",
    "    with open(comparacao_path, 'r', encoding='utf-8') as f:\n",
    "        comparacao = json.load(f)\n",
    "    \n",
    "    stats = comparacao.get('estatisticas_por_modelo', {})\n",
    "    ranking = comparacao.get('ranking_modelos', [])\n",
    "    \n",
    "    # Modelo vencedor\n",
    "    if ranking:\n",
    "        vencedor = ranking[0]['modelo']\n",
    "        display(Markdown(f\"## üèÜ Modelo Vencedor: **{vencedor}**\"))\n",
    "    \n",
    "    # Tabela comparativa\n",
    "    data = []\n",
    "    for modelo, stat in stats.items():\n",
    "        data.append({\n",
    "            'Modelo': modelo,\n",
    "            'Faithfulness': f\"{stat['faithfulness_media']:.3f}\",\n",
    "            'Relevancy': f\"{stat['answer_relevancy_media']:.3f}\",\n",
    "            'Context Precision': f\"{stat.get('context_precision_media', 0.0):.3f}\",\n",
    "            'ROUGE-1': f\"{stat['rouge_1_f1_media']:.3f}\",\n",
    "            'BERTScore': f\"{stat['bertscore_f1_media']:.3f}\",\n",
    "            'Tempo M√©dio (s)': f\"{stat['tempo_resposta_medio']:.2f}\"\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    display(Markdown(\"## üìä Compara√ß√£o de Modelos\"))\n",
    "    display(df)\n",
    "    \n",
    "    # Issues identificados\n",
    "    with open(results_path, 'r', encoding='utf-8') as f:\n",
    "        resultados = json.load(f)\n",
    "    \n",
    "    issues_por_modelo = {}\n",
    "    for res in resultados:\n",
    "        modelo = res['modelo']\n",
    "        issues = res.get('issues', [])\n",
    "        if issues:\n",
    "            if modelo not in issues_por_modelo:\n",
    "                issues_por_modelo[modelo] = []\n",
    "            issues_por_modelo[modelo].extend(issues)\n",
    "    \n",
    "    if issues_por_modelo:\n",
    "        display(Markdown(\"## ‚ö†Ô∏è Issues Identificados\"))\n",
    "        for modelo, issues in issues_por_modelo.items():\n",
    "            display(Markdown(f\"**{modelo}:**\"))\n",
    "            for issue in issues:\n",
    "                display(Markdown(f\"- {issue}\"))\n",
    "    else:\n",
    "        display(Markdown(\"## ‚úÖ Nenhum Issue Identificado\"))\n",
    "\n",
    "except Exception as e:\n",
    "    display(Markdown(f\"**Erro ao carregar resultados:** {e}\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
